## 操作系统



### 进程和线程的区别和联系

**区别**

1. 



### 什么时候使用多线程？什么时候使用多进程？

**使用多线程**：

* 如果
* 

### 线程共享什么变量？独占什么变量？

每个线程都有一个独立的线程上下文，包括以下内容：线程ID、程序计数器、栈、栈顶指针、条件码、通用目的寄存器值。

所有线程共享其余的进程上下文，包括以下内容：只读文本（代码）、读/写数据、堆、共享库代码和数据区域。同时，所有的线程共享打开的文件描述符集合。

### 进程的生命周期

**三状态版本**

<img src="images/image-20200917141320210.png" alt="image-20200917141320210" style="zoom:50%;" />

* **运行**：进程正在处理器上运行，执行指令。
* **就绪**：进程可以运行，但由于某些原因，操作系统不选择此时运行该进程。
* **阻塞**：一个进程执行了某个操作，直到完成后才会继续运行。常见的操作是I/O操作。

**五状态版本**



### 进程控制块

Linux使用

### 用户模式和内核模式

用户态中的进程不能执行任何特权指令，这些特权指令包括停止处理器、改变模式位、执行I/O操作等。而在内核态中，一个进程可以执行任何指令，并且可以访问系统中任意位置的内存。

用户模式和内核模式之间的切换方式：系统调用、中断、陷阱。

* 系统调用
* 中断
* 陷阱

区别用户模式和内核模式的原因在于，操作系统需要提供一种高效可控的进程抽象，需要限制进程可以执行的指令以及可以访问的内存地址范围。

### 上下文切换

内核通过上下文切换实现多任务。



### fork、vfork、clone

fork是Linux中创建一个新进程的方法。fork调用一次，但会返回两次。在子进程中返回值为0，在父进程中返回值为子进程的pid。子进程是父进程的复制，并不共享数据空间、栈，只共享代码段。由于子进程在fork后通常执行exec，Linux对fork的实现进行了写时拷贝的优化，如果子进程或者父进程试图修改一个内存区域，内核只为这个区域制作一块副本。

vfork和fork功能一致，但是在语义上有两点不同：

1. 由于vfork用于父进程fork之后子进程立刻执行exec，所以子进程部分复制父进程的地址空间。如果子进程修改数据、调用函数、没有执行exec就退出，会带来未知的后果。
2. 保证子进程先执行。

clone提供了一种更加精细化的控制，可以由用户决定父子进程之间共享哪些区域。Linux的进程创建和线程创建都用到了clone。

* fork等价于clone()
* pthread_create等价于clone

在底层实现中，clone调用do_fork完成大部分工作，do_fork调用copy_process，然后进程开始执行。copy_process的过程如下：

1. 为新进程创建一个内核栈、thread_info结构和task_struct结构。
2. 检查创建了子进程后，当前用户拥有的进程数目是否超过了系统的资源限制。
3. 子进程把自己和父进程区分开。把大部分进程描述符的成员设为0或者初始化。
4. 设置子进程的状态，保证不会被投入运行。
5. 设置子进程task_struct的flags标志位。
6. 为子进程分配一个有效的pid。
7. 根据clone()的参数，拷贝或者共享打开的文件、文件系统信息、信号处理函数、进程地址空间、命名空间。一般给定进程的所有线程共享这些信息，而不同的进程需要拷贝这些信息。
8. 执行收尾工作并且返回指向子进程的指针。

### 系统调用的执行过程

在用户模式下，进程不能直接执行一些内核代码，需要使用一种手段通知内核用户需要执行系统调用了，让内核执行系统调用的代码。这种通知时通过软中断实现的，通过引发一个异常让内核执行对应的异常处理程序。中断号128对应了系统调用处理程序。

在执行系统调用处理程序时，必须知道对应的系统调用是哪一个，这个数字通过参数进行传递，在x86平台上，该参数存储在eax寄存器中。系统调用处理程序验证了系统调用的有效性后，执行对应的系统调用。每个系统调用都需要一定的参数，这些参数存储在寄存器中。系统调用的返回值存储在eax寄存器中。

### 中断



### 进程调度算法

进程调度需要尽可能优化以下两个目标：
* **响应时间**：任务首次执行时间减去任务到达时间。
* **周转时间**：任务完成时间减去任务到达时间。

进程调度算法包括先来先服务、最短任务优先、最短完成时间有限、轮转调度、多级反馈队列调度。

**先来先服务（First Come First Server, FCFS）**

按照任务到达时间进行调度。简单，易于实现。会造成耗时较少的任务排在耗时较多任务后面。

**最短任务优先（Shortest Job First, SJF）**

先运行第一个到达的任务，然后运行第二个到达的任务，依此类推。如果所有任务同时到达，可以保证是最优调度。如果任务可以随时到达，不能保证结果最优。

**最短完成时间优先（Shortest Time-to-Completion First, STCF）**

最短任务优先的抢占式版本。每当新任务来临时，判断剩余任务和新任务中那个剩余时间最短，然后调度该任务。平均周转时间大大提升。在响应时间上表现不佳。

**轮转调度（Round-Robin, RR）**

每个任务运行一段固定的时间片，然后换到下一个任务。可以保证响应时间。在平均周转时间上表现不佳。需要选取合适的时间片长度。时间片越短表现越好，但是上下文切换成本越高。

**多级反馈队列调度（Multi-Level Feedback Queue, MLFQ） **

使用多级队列表示优先级，并利用反馈信息决定每个任务当前的优先级。它不需要使用先验知识，而是通过观察工作的运行给出对应的优先级。在运行过程中，使用如下的策略调整优先级：

* 若A优先级高于B，运行A；若A和B优先级相同，轮转运行。
* 任务刚到达时，放在最高优先级。
* 一旦任务用完了在某个优先级的时间配额（无论中间放弃多少次），降低优先级。
* 经过一段时间，将系统的所有任务调回最高优先级，以免进程长期得不到调度产生“饿死”现象。

### Linux CFS（完全公平调度）

 

### 进程地址空间

<img src="images/image-20200918193032889.png" alt="image-20200918193032889" style="zoom:50%;" />

进程地址空间分为以下几个部分：

* 代码段：存放二进制代码
* 初始化数据段：存放已经初始化的变量和数据。
* 未初始化数据段：存放没有初始化的变量和数据。
* 堆
* 栈

### 虚拟内存实现机制

虚拟内存采用段页结合的方式进行管理。

**分段**



**分页**

操作系统把内存空间分割成了固定大小的单元，这种思想称之为分页，每一个单元称为一个页。分页的优势有两点：

* 灵活性：操作系统无需知道一个进程如何使用内存空间，能高效提供内存地址抽象。
* 简单性：管理空闲空间更加简便。这些空闲空间没有必要映射到连续的物理内存上，仅需要拿出数量相同的空闲页即可。

从虚拟地址到物理地址的转换由MMU完成，同时，操作系统在内存中为每个进程保存了一个页表，页表的每一项是一个虚拟地址到物理地址的映射。页表存放在物理内存中。一个虚拟地址可以分为两个部分：虚拟页面号和页内偏移量。

当执行地址翻译时，首先从虚拟地址中获取虚拟页号，到页表中找出对应的物理页号，结合页内偏移量得到物理地址。最后利用真正的物理地址得到数据。

**TLB**

使用分页机制存在的问题之一是系统运行速度过慢。TLB可以用于加速地址转换过程。它将频繁发生的虚拟地址和物理地址的转换缓存。

当执行地址翻译时，首先从虚拟地址中获取虚拟页号，然后检查TLB中是否有该页号的转换映射。
* 如果有（TLB hit），直接从TLB中得到物理页号，和偏移量结合得到物理地址。
* 否则，硬件访问页表寻找转换映射，并用该映射更新TLB，完成更新后，重新尝试执行地址翻译的指令。

**多级页表**

多级页表的目的是解决页表占用内存过多的现象，可以去掉大部分页表中的无效项，不要留在内存中。

多级页表的基本思想如下：
* 将页表分割成页大小的单元。
* 如果整页的页表无效，那么不会在内存中分配页表的存储空间。
* 使用页目录表项表示整个页的页表包不包含有效页。

### 页面置换

为了支持巨大的虚拟地址空间，操作系统需要把目前暂时没有用的页缓存起来。一般缓存位置位于磁盘。

如果程序访问的虚拟地址对应的物理地址不存在，就需要通过操作系统处理。这种错误称为页错误，操作系统需要调用缺页处理程序处理（缺页异常处理程序）。为了处理页错误，操作系统采取以下的流程：

* 操作系统需要为换入的页寻找一个物理页。
* 如果没有空闲的物理页，操作系统需要运行页面置换算法，从内存中踢出一些页。
* 通过I/O请求读取该页。
* 更新页表，重新执行需要翻译虚拟地址的指令。

### 常用页面置换算法

**最优替换**

该算法所选择的被换出的页面将是最长时间内不再被访问，通常可以保证获得最低的缺页率。这是一种理论上的算法，因为无法知道一个页面多长时间不再被访问。

**先进先出**

选择换出的页面是最先进入的页面。该算法会将那些经常被访问的页面也被换出，从而使缺页率升高。

**最近最久未使用（LRU）**

算法思路在于，虽然无法知道将来要使用的页面情况，但是可以知道过去使用页面的情况。LRU 将最近最久未使用的页面换出。

为了实现LRU，需要在内存中维护一个所有页面的链表。当一个页面被访问时，将这个页面移到链表表头。这样就能保证链表表尾的页面是最近最久未访问的。因为每次访问都需要更新链表，因此这种方式实现的LRU代价很高。

**时钟算法**



### LRU代码实现

```c++
class LRUCache {
public:
    LRUCache(int capacity) {
        this->capacity = capacity;
    }
    
    int get(int key) {
        if (mapping.count(key) == 0) {
            return -1;
        } else {
            int value = mapping[key]->second;
            elements.erase(mapping[key]);
            elements.push_front({key, value});
            mapping[key] = elements.begin();
            return value;
        }
    }
    
    void put(int key, int value) {
        if (mapping.count(key) != 0) {
            elements.erase(mapping[key]);
        } else {
            if (elements.size() == capacity) {
                int del = elements.back().first;
                elements.pop_back();
                mapping.erase(del);
            }
        }
        elements.push_front({key, value});
        mapping[key] = elements.begin();
    }

private:
    int capacity;
    unordered_map<int, list<pair<int, int>>::iterator> mapping;
    list<pair<int, int>> elements;
};
```

**关键点**

使用两个数据结构：双向链表和哈希表。

### malloc底层实现

[https://blog.csdn.net/maokelong95/article/details/51989081](https://blog.csdn.net/maokelong95/article/details/51989081)

malloc通过两个系统调用实现：`brk`和`mmap`。

brk

mmap





### 动态内存分配策略

* 最优匹配：遍历空闲链表，找到所有大于等于请求内存大小的空闲块，把其中最小的一块分配出去，剩余的内存添加到空闲链表中。
* 最差匹配：和最优匹配相反，找到空闲链表中最大的一块空闲内存，然后把剩余的空闲内存加入到空闲链表中。
* 首次匹配：遍历空闲链表，直到遇上一个满足内存要求的空闲内存块。
* 下次匹配：和首次匹配类似，区别在于下次匹配需要记录上次匹配成功的空闲链表索引，搜索空闲链表时，从这个索引开始。这种方法避免对内存首部的频繁分配与释放。

### 内部碎片和外部碎片

当分配的内存被释放后，可用的内存空间会被分为不连续的小块，这个时候容易产生外部碎片问题。如果空闲内存的总量超过了申请的内存大小，但是由于这些内存并不连续，最后导致内存分配失败，这种情况称为外部碎片。

如果分配程序给出的内存超过了请求的大小，已分配的内存中未被使用的部分就是内存碎片。这种形式的狼诶发生在已分配单元的内部。

### Linux伙伴系统



### slab内存分配器

slab用于内核数据结构的分配和释放，可以加快内存的分配和释放速度。



### 字节对齐

字节对齐的作用是提高系统的性能。如果一个数据没有对齐，那么需要更多的内存读取次数。

字节对齐遵循的原则是，任何K字节的基本对象的起始地址必须是K的倍数。如果在结构体中，需要在字段中插入间隙，保证每个字段都能满足对齐要求。另外，结构体的末尾也有可能需要填充字符，保证在数据中，每个元素满足对齐要求。

### 字节序

字节序分为大端序和小端序。大端序表明最高有效位在最前面，小端序表明最低有效位在最前面。

判断字节序的代码

```C
#include <stdio.h>

```

字节序主要用在网络编程中，保证所有主机发送内容的字节序都是一致的。网络字节序是大端序。

### 进程间通信

进程间通信有以下五种方式：管道、消息队列、共享内存、信号量、套接字。

**管道**



### 线程同步

线程同步有以下几种方式：互斥量、条件变量、读写锁、自旋锁、屏障。

**互斥量**



### 互斥量的实现



### 为什么条件变量要配合互斥量使用？

为了保护条件变量检查的条件。

假设有下面的代码，父线程调用thr_join, 子线程调用thr_exit。
```C
void thr_exit() {
    done = 1;
    pthread_cond_signal(&c);
}

void thr_join() {
    if (done == 0) {           // p1
        pthread_cond_wait(&c); // p2
    }
}
```
若父线程执行完p1后，操作系统调度子线程执行。子线程执行完毕后退出。此时，父线程继续执行，当执行p2时休眠。在这种情况下，不会有任何线程能够唤醒父线程（此时只有一个线程正在运行），父线程会**一直睡眠**，无法被唤醒。

### 生产者-消费者问题

**基于互斥量和条件变量**

```C
void *producer(void *arg) {
    int i;
    for (i = 0; i < loops; i++) {
    	Mutex_lock(&m);            // p1
    	while (num_full == max)    // p2
    	    Cond_wait(&empty, &m); // p3
    	do_fill(i);                // p4
    	Cond_signal(&fill);        // p5
    	Mutex_unlock(&m);          // p6
    }

    // end case: put an end-of-production marker (-1) 
    // into shared buffer, one per consumer
    for (i = 0; i < consumers; i++) {
    	Mutex_lock(&m);
    	while (num_full == max) 
    	    Cond_wait(&empty, &m);
    	do_fill(-1);
    	Cond_signal(&fill);
    	Mutex_unlock(&m);
    }

    return NULL;
}
                                                                               
void *consumer(void *arg) {
    int tmp = 0;
    // consumer: keep pulling data out of shared buffer
    // until you receive a -1 (end-of-production marker)
    while (tmp != -1) { 
    	Mutex_lock(&m);           // c1
    	while (num_full == 0)     // c2 
    	    Cond_wait(&fill, &m); // c3
    	tmp = do_get();           // c4
    	Cond_signal(&empty);      // c5
    	Mutex_unlock(&m);         // c6
    }
    return NULL;
}

```

关键点：

* 使用**一个互斥锁**保护临界区数据的读写。
* 使用 `while` 判断条件变量唤醒条件是否满足，防止虚假唤醒。
* 使用**两个条件变量**，保证生产者只能唤醒消费者，消费者只能唤醒生产者。

**基于信号量**



### 死锁

在多进程环境中，若每个进程分别持有特定资源，并且等待其他进程释放持有的资源，在为改变状态的情况下一直保持下去，就会造成死锁。

造成死锁的条件有如下几点：

* 互斥：每种资源只能由一个进程持有。
* 持有并等待：进程持有了资源，并且等待其他进程持有的资源。
* 非抢占： 进程获得的资源不能被抢占。
* 循环等待：进程之间存在一条环路，每个进程持有一个资源，并且等待下一个进程持有的资源。

解决死锁的方法主要有以下几点：死锁预防、死锁避免、死锁检测和恢复。

**死锁预防**

核心思想是破坏产生死锁的四个条件。
* 循环等待：安排锁的获取顺序以避免死锁。
* 持有并等待：通过原子地抢锁解决。实际中，通过提供一个全局锁，保证代码在抢锁的过程中不会出现不合时宜的线程切换。
* 非抢占：系统提供了trylock()方法，会尝试获得锁，如果失败，返回-1。这种方法可能会造成**活锁**，两个线程一直重复这段序列，又都同时抢锁失败。
* 互斥：基于硬件指令，构造无锁数据结构完成相同的功能，例如**CAS（compare-and-swap）**指令。

**死锁避免**

提前获取每个进程关于资源的使用信息，通过调度的方式避免死锁。可以采用诸如银行家算法完成。这类方法的局限性在于适用场景有限并且会限制系统的并发数。

**死锁检测和恢复**

允许死锁发生，系统定期检查是否存在死锁情况，如果存在死锁就执行恢复程序。这种方法在数据库系统中有应用。

### I/O模型

Linux的I/O模型分为五种：阻塞I/O、非阻塞I/O、多路复用I/O、信号驱动I/O、异步I/O。

