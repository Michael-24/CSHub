## 操作系统



### 进程和线程的区别和联系

1. 进程是对运行时程序的封装，是系统进行资源分配和调度的基本单元，而线程是进程的子任务，是CPU分配和调度的基本单元。
2. 进程拥有一个完整的资源平台，而线程只独享必不可少的资源，如寄存器和栈；
3. 线程之间可以通过全局变量通信，而进程之间需要使用IPC通信。
4. 线程同样具有状态之间的转换关系，线程能共减少并发执行的时间和空间开销。
5. 如果一个线程崩溃，会影响到同一个进程中的其他线程，而一个进程崩溃不会影响到其他进程。

线程能够减少开销，体现在以下几个方面：

1. 线程的创建和销毁时间更快。进程在创建的过程中，还需要复制资源的管理信息，而线程之间共享这些信息。同理，线程释放的资源相比进程少很多。
2. 同一个进程中的线程切换比进程切换更快。线程拥有相同的地址空间，意味着线程之间的切换不需要切换页表；进程之间的切换，需要切换也表，这个过程的开销是比较大的（涉及到TLB的失效）。
3. 线程由于共享地址空间，可以通过全局变量通信，不需要经过内核，数据的交互效率更高。

**Linux系统中的实现**

在Linux操作系统中，进程和线程之间的最重要区别是是否共享地址空间。

在创建线程的过程中，Linux仅仅把新线程`task_struct`的mm域指向主线程的`mm_struct`地址，这样保证同一个进程中的线程共享内存地址空间。

```C
if (clone_flag & CLONE_VM) {
  atomic_inc(&current->mm->mm_users);
  tsk->mm = current->mm
}
```

除此之外，进程和线程之间的实现没有本质区别，Linux进程是一个轻量级的进程。

### 什么时候使用多线程？什么时候使用多进程？

可以使用多线程的场景如下：

* 如果需要共享大量的数据，使用多线程；反之，使用多进程保证程序编写的简单性。
* 如果需要频繁的创建和销毁，使用多线程。
* 如果需要利用多核加速，使用多线程；如果需要使用分布式技术支持可扩展，使用多进程。

### 线程共享什么变量？独占什么变量？

独占资源：

* 线程ID，用于唯一标识线程。
* 程序计数器：当前线程执行到哪里了。
* 栈：每个线程的调用是独立的。
* 错误返回码：系统调用或库函数发生错误时，会设置全局变量 errno，各个线程的错误返回码应该是独立的。
* 通用目的寄存器。

共享资源：

* 只读文本（代码）。
* 读/写数据。
* 堆。
* 共享库代码和数据区域。
* 文件描述符表。
* ...

### 进程的生命周期

<div align="center">
  <img src="images/image-20200917141320210.png">
</div>



* **运行**：进程正在处理器上运行，执行指令。
* **就绪**：进程可以运行，但由于某些原因，操作系统不选择此时运行该进程。
* **阻塞**：一个进程执行了某个操作，直到完成后才会继续运行。常见的操作是I/O操作。

### Linux下的进程状态



### fork/vfork/clone（进程创建过程）

fork是Linux中创建一个新进程的方法。fork调用一次，但会返回两次。在子进程中返回值为0，在父进程中返回值为子进程的pid。子进程是父进程的复制，并不共享数据空间、栈，只共享代码段。由于子进程在fork后通常执行exec，Linux对fork的实现进行了写时拷贝的优化，如果子进程或者父进程试图修改一个内存区域，内核只为这个区域制作一块副本。

vfork和fork功能一致，但是在语义上有两点不同：

1. 由于vfork用于父进程fork之后子进程立刻执行exec，所以子进程部分复制父进程的地址空间。如果子进程修改数据、调用函数、没有执行exec就退出，会带来未知的后果。
2. 保证子进程先执行。

clone提供了一种更加精细化的控制，可以由用户决定父子进程之间共享哪些区域，通过flags参数控制进程（线程）之间的共享程度。Linux的线程创建都用到了clone。

* fork等价于clone(SIGCHLD)
* pthread_create等价于clone()
* vfork等价于clone()

在底层实现中，clone调用do_fork完成大部分工作，do_fork调用copy_process，然后进程开始执行。copy_process的过程如下：

1. 为新进程创建一个内核栈、thread_info结构和task_struct结构。
2. 检查创建了子进程后，当前用户拥有的进程数目是否超过了系统的资源限制。
3. 子进程把自己和父进程区分开。把大部分进程描述符的成员设为0或者初始化。
4. 设置子进程的状态，保证不会被投入运行。
5. 设置子进程task_struct的flags标志位。
6. 为子进程分配一个有效的pid。
7. 根据clone()的参数，拷贝或者共享打开的文件、文件系统信息、信号处理函数、进程地址空间、命名空间。一般给定进程的所有线程共享这些信息，而不同的进程需要拷贝这些信息。
8. 执行收尾工作并且返回指向子进程的指针。

### 进程终止的几种方式

五种正常方式：

* main函数执行return语句。
* 执行exit函数，刷新I/O缓冲流。
* 执行`_exit`或者`_Exit`函数，不刷新I/O缓冲流。
* 进程的最后一个线程执行return语句。进程的返回值是0。
* 进程的最后一个线程执行pthread_exit函数。

三种异常方式：

* 进程调用abort，产生一个SIGABRT信号。
* 进程接收到某个信号。
* 进程的最后一个线程调用pthread_cancel函数。

### 用户模式和内核模式

用户态中的进程不能执行任何特权指令，这些特权指令包括停止处理器、改变模式位、执行I/O操作等。而在内核态中，一个进程可以执行任何指令，并且可以访问系统中任意位置的内存。

用户模式和内核模式之间的切换方式：系统调用、中断、陷阱。

区别用户模式和内核模式的原因在于，操作系统需要提供一种高效可控的进程抽象，需要限制进程可以执行的指令以及可以访问的内存地址范围。

### 上下文切换

内核为每个进程都维护了一个上下文，上下文保存了内核为了恢复一个正在运行的进程所需要的全部状态。通常，进程上下文不仅包含了用户栈、全局变量等用户态空间资源，程序计数器、通用寄存器、浮点寄存去等CPU上下文内容，还包括括了内核栈、内核数据结构（页表、文件表等）等内核空间资源。

为了实现进程上下文的切换，通常会把交换的信息保存在进程的PCB中，当运行另外一个进程的时候，从这个进程的 PCB 取出上下文并恢复，这使得这个进程可以继续执行。

进程的上下文切换会在以下几个时间点发生：

* 当某个进程的时间片耗尽，就会被内核挂起，切换到其他等待的进程。
* 如果进程在执行系统调用的过程中，需要等待某个条件满足后才能执行，此时内核就会挂起该线程，调度另一个进程执行。
* 发生硬件中断时，CPU 上的进程会被中断挂起，转而执行内核中的中断服务程序。

如果在两个线程之间发生上下文切换，根据是否同属于一个线程，执行不同的操作：

* 如果两个线程不是属于同一个进程，切换的过程就跟进程上下文切换一样。
* 如果两个线程属于一个进程，由于共享地址空间，切换过程中虚拟内存之类的资源保持不变，只需要切换线程的私有数据、寄存器等不共享变量，避免了TLB的失效，速度更快。

#### Linux中的实现步骤

上下文切换主要实现以下两个步骤：

* 切换页全局目录，安装一个新的地址空间。
* 切换内核态堆栈和硬件上下文（硬件上下文提供了执行新进程需要的所有信息）。

### 系统调用的执行过程

在用户模式下，进程不能直接执行一些内核代码，需要使用一种手段通知内核用户需要执行系统调用了，让内核执行系统调用的代码。这种通知时通过软中断实现的，通过引发一个异常让内核执行对应的异常处理程序。中断号128对应了系统调用处理程序。

系统调用通常定义了零个或者多个参数，并定义了一个long类型的返回值。Linux通过系统调用号区分不同的系统调用，当需要执行一个系统调用时，这个系统调用号指明了指明了

在执行系统调用处理程序时，必须知道对应的系统调用号是哪一个，这个数字通过参数进行传递，在x86平台上，该参数存储在eax寄存器中。系统调用处理程序验证了系统调用的有效性后，执行对应的系统调用。每个系统调用都需要一定的参数，这些参数存储在寄存器中。系统调用的返回值存储在eax寄存器中。

### Linux中异常和中断的区别

* 中断（异步异常/硬件异常）：由处理器外面发生的事情引起的事件。对于执行程序，这些完全是异步的，因为不知道什么时候会发生，CPU的响应也是完全被动的。比较常见的中断有两种：计时器中断和 I/O 中断。计时器中断是由计时器芯片每隔几毫秒触发的，内核用计时器终端来从用户程序手上拿回控制权。I/O 中断类型比较多样，比方说键盘输入了 ctrl-c，网络中一个包接收完毕，都会触发这样的中断。

* 异常（同步异常）：是因为执行某条指令所导致的事件，分为陷阱、故障和终止，他们的区别如下。

  | 类型 |       原因       |       行为       |        示例        |
  | :--: | :--------------: | :--------------: | :----------------: |
  | 陷阱 |    有意的异常    | 返回到下一条指令 |      系统调用      |
  | 故障 | 潜在可恢复的错误 |  返回到当前指令  | 页故障(page fault) |
  | 终止 |  不可恢复的错误  |   终止当前进程   |      非法指令      |

### 进程调度算法

进程调度需要尽可能优化以下两个目标：
* **响应时间**：任务首次执行时间减去任务到达时间。
* **周转时间**：任务完成时间减去任务到达时间。

#### 单处理器调度

在单核处理器上，进程调度算法包括先来先服务、最短任务优先、最短完成时间有限、轮转调度、多级反馈队列调度、公平调度。

##### 先来先服务

按照任务到达时间进行调度。简单，易于实现。会造成耗时较少的任务排在耗时较多任务后面。

##### 最短任务优先

先运行第一个到达的任务，然后运行第二个到达的任务，依此类推。如果所有任务同时到达，可以保证是最优调度。如果任务可以随时到达，不能保证结果最优。

##### 最短完成时间优先

最短任务优先的抢占式版本。每当新任务来临时，判断剩余任务和新任务中那个剩余时间最短，然后调度该任务。平均周转时间大大提升。在响应时间上表现不佳。

##### 轮转调度

每个任务运行一段固定的时间片，然后换到下一个任务。可以保证响应时间。在平均周转时间上表现不佳。需要选取合适的时间片长度。时间片越短表现越好，但是上下文切换成本越高。

##### 多级反馈队列调度 

使用多级队列表示优先级，并利用反馈信息决定每个任务当前的优先级。它不需要使用先验知识，而是通过观察工作的运行给出对应的优先级。在运行过程中，使用如下的策略调整优先级：

* 若A优先级高于B，运行A；若A和B优先级相同，轮转运行。
* 任务刚到达时，放在最高优先级。
* 一旦任务用完了在某个优先级的时间配额（无论中间放弃多少次），降低优先级。
* 经过一段时间，将系统的所有任务调回最高优先级，以免进程长期得不到调度产生“饿死”现象。

**彩票调度**

每个进程按照优先级分配一个范围的彩票值。调度器知道彩票数值的综合，调度的过程中

#### 多处理器调度

现代处理器基本都是多核的，所以现代的调度算法基本上是适应了多核的需要的。在多处理器体系结构上主要有这调度算法算法：单队列多处理器调度、多队列多处理器调度

##### 单队列多处理器调度

这种方法是对于单处理器调度算法的扩展，每个核共享一个调度队列，每当需要调度的时候从队列中取出一个任务调度。

这种方法的优势在于实现简单，但是也有两个缺点：一是缺乏扩展性，每个处理器需要通过加锁保证并发访问调度队列；二是缓存亲和度不够，有可能一个任务被调度到不同的处理器上执行，导致CPU缓存没有数据，缓存亲和度不够。

##### 多队列多处理器调度

在这种调度方法中，每个处理器都会有一个自己的调度队列，每个调度队列都可以使用自己的调度规则。当一个新任务到来时，系统通过一些启发式规则，将其放入到某个调度队列中。

和单队列调度方法相比，多队列调度方法不需要访问共享的调度队列，减少了加锁和解锁的开销；并且每个任务都固定在一个处理器上，缓存亲和度更高。

多队列调度的一个潜在问题是负载不均，为了解决这个问题，可以让任务跨处理器迁移，实现真正的负载均衡。系统采用工作窃取的方式实现任务迁移。工作负载较小的处理器不定时“偷看”其他处理器的负载，如果一个处理器负载显著性更高，就“窃取”其中的任务。

### Linux CFS（完全公平调度）

在Linux 2.6.23以后，Linux采用CFS（完全公平调度）作为系统的默认调度算法。

 相较于其他的调度方法，CFS有以下的特点：

* 不同于其他的调度算法需要一个固定的时间片大小，CFS使用vruntime（虚拟运行时间）表示每个进程的运行时间，达到公平划分CPU时间的目的。每次进程调度的时候选择vruntime最小的进程运行。所有进程vruntime的增长速率是一致的。操作系统利用sched_latency（一般为48ms）计算每个进程的时间片。同时，操作系统通过参数min_granularity保证一个进程最少需要运行多久（一般为6ms）。
* 通过nice值控制所有进程的调度权重。通过sched_latency结合nice值加权的方式求出每个进程应该得到的时间片，vruntime通过以前的vruntime、真实的运行时间以及nice值进行更新，保证了不同权重的进程vruntime增长速率和权重是一致的。
* 采用红黑树组织所有的可调度进程。红黑树采用vruntime作为键值排序，可以高效的找到vruntime最小的进程，调度执行。
* 如果一个I/O进程等待时间过长，会导致vruntime过小从而一直被调度运行，其他的进程无法被调度。因此，在一个进程被唤醒后，系统把它的vruntime修改为当前最小的vruntime，保证尽可能不出现进程饥饿现象。

### 僵尸进程、孤儿进程、守护进程

#### 僵尸进程

如果一个子进程先于父进程退出，但是父进程还没有对其进行状态收集，这个子进程就是一个僵尸进程。这些子进程的进程描述符还会保留在系统中，记载该进程的进程ID、终止状态以及资源利用信息(CPU时间，内存使用量等等)供父进程收集，除此之外，僵尸进程不再占有任何内存空间。这个僵尸进程可能会一直留在系统中直到系统重启。

如果僵尸进程过多，那么最终系统资源（进程ID号、分配进程描述符需要的内存）就会耗尽，一个系统无法再创建新的子进程。

处理僵尸进程的方法有以下几种：

* 父进程调用wait或者waitpid函数，等待子进程退出，然后回收子进程的资源。wait系统调用会使父进程暂停执行，直到它的一个子进程结束为止。waitpid则可以加入WNOHANG(wait-no-hang)选项，如果没有发现结束的子进程，就会立即返回，不会将调用waitpid的进程阻塞。waitpid还可以选择是等待任一子进程（同wait），还是等待指定pid的子进程，还是等待同一进程组下的任一子进程，还是等待组ID等于pid的任一子进程。
* 父进程先于子进程退出，子进程的父进程转为1号进程，由该进程负责子进程的资源释放，1号进程保证其子进程退出后会回收子进程的资源。
* 当子进程退出的时候，会向父进程发送SIGCHLD信号，父进程可以注册一个信号处理函数，在这个函数中调用waitpid函数，等待所有结束的子进程（一般需要循环等待，因为可能有多个子进程已经结束，而信号处理函数只能执行一次，需要保证所有的子进程都被回收完毕）。

#### 孤儿进程

如果父进程先于子进程退出，那么这个子进程就是一个孤儿进程。孤儿进程会被init进程收养并完成状态收集。

#### 守护进程

守护进程是一个

### 进程地址空间

<div align="center">
  <img src="images/image-20200918193032889.png">
</div>

进程地址空间分为以下几个部分：

* 代码段：存放二进制代码
* 初始化数据段：存放已经初始化的变量和数据。
* 未初始化数据段：存放没有初始化的变量和数据。
* 堆
* 栈

### 虚拟内存实现机制

虚拟内存采用分页的方式实现。

#### 分页

操作系统把内存空间分割成了固定大小的单元，这种思想称之为分页，每一个单元称为一个页。分页的优势有两点：

* 灵活性：操作系统无需知道一个进程如何使用内存空间，能高效提供内存地址抽象。
* 简单性：管理空闲空间更加简便。这些空闲空间没有必要映射到连续的物理内存上，仅需要拿出数量相同的空闲页即可。

从虚拟地址到物理地址的转换由MMU完成，同时，操作系统在内存中为每个进程保存了一个页表，页表的每一项是一个虚拟地址到物理地址的映射。页表存放在物理内存中。一个虚拟地址可以分为两个部分：虚拟页面号和页内偏移量。

当执行地址翻译时，首先从虚拟地址中获取虚拟页号，到页表中找出对应的物理页号，结合页内偏移量得到物理地址。最后利用真正的物理地址得到数据。

#### TLB

使用分页机制存在的问题之一是系统运行速度过慢，这个问题可以使用TLB解决。TLB可以用于加速地址转换过程。它将频繁发生的虚拟地址和物理地址的转换缓存。

当执行地址翻译时，首先从虚拟地址中获取虚拟页号，然后检查TLB中是否有该页号的转换映射。
* 如果有（TLB hit），直接从TLB中得到物理页号，和偏移量结合得到物理地址。
* 否则，硬件访问页表寻找转换映射，并用该映射更新TLB，完成更新后，重新尝试执行地址翻译的指令。

当TLB未命中时，有两种处理方式：

* 硬件：硬件知道页表的位置与格式，遍历页表，找到正确的表项并更新TLB。（代表指令集：x86）
* 软件：触发中断，操作系统通过陷阱指令的方式更新TLB中的表项，然后重新执行指令。（代表指令集：RISC-V）

进程间上下文切换的时候需要刷新TLB中的内容。一种思路是在上下文切换时直接清空TLB中的内容，进程不会读到错误的地址，但是会造成一定程度的开销（会触发TLB不命中）。如果频繁进行上下文切换，会导致开销很大。

有些系统通过硬件支持避免这种情况，实现跨进程上下文的TLB共享。一种做法是采用地址空间标识符缓存不同进程的地址空间映射。

TLB通常采用LRU替换策略。

#### 多级页表

多级页表的目的是解决页表占用内存过多的现象，可以去掉大部分页表中的无效项，不要留在内存中。

多级页表的基本思想如下：
* 将页表分割成页大小的单元。
* 如果整页的页表无效，那么不会在内存中分配页表的存储空间。
* 使用页目录表项告知使用页表的页或者整个页的页表包不包含有效页。

多级页表的优势如下：

* 多级页表通常很紧凑，并且支持稀疏的地址空间。
* 页表的每一部分可以整齐的放在一页中，更容易管理内存。

### 交换空间与虚拟内存的联系

交换空间位于磁盘上，目的是为了把内存中暂时用不到的页放置到磁盘中，等待需要使用的时候再换回到内存中。交换空间相较于内存有更大的容量，但是访问速度会更慢。交换空间的大小是很重要的，他的大小决定了操作系统在某一时刻能够使用的最大内存页数。

交换空间不是硬盘交换的唯一目的地，操作系统在页面数量不足时，可以选择使用一些只读页的空间换出（如代码页），这些页不会被应用程序修改，无需写会到磁盘，在需要使用的时候可以重新从磁盘上加载。

### 页面置换

为了支持巨大的虚拟地址空间，操作系统需要把目前暂时没有用的页缓存起来。一般缓存位置位于磁盘。

如果程序访问的虚拟地址对应的物理地址不存在，就需要通过操作系统处理。这种错误称为页错误，操作系统需要调用缺页处理程序处理（缺页异常处理程序）。

操作系统需要知道虚拟地址对应的物理页的磁盘地址，这样才能在处理缺页错误时找到物理页并从磁盘加载到内存中。

为了处理页错误，操作系统采取以下的流程：

* 操作系统需要为换入的页寻找一个物理页。
* 如果没有空闲的物理页，操作系统需要运行页面置换算法，从内存中踢出一些页。
* 通过I/O请求读取该页。
* 更新页表，重新执行需要翻译虚拟地址的指令。

Linux的缺页异常处理程序执行以下的步骤：

1. 判断虚拟地址是否合法。
2. 判断对虚拟地址的访问是否合法。
3. 经过上面两个步骤，操作系统已经确定了当前的指令是合法指令。选择一个牺牲页面，换入新的页面并更新页表。
4. 重新执行访问该地址的指令。

通常，操作系统会提前把一些页面换出去，用以提升性能。

### 常用页面置换算法

#### **最优替换**

该算法所选择的被换出的页面将是最长时间内不再被访问，通常可以保证获得最低的缺页率。这是一种理论上的算法，因为无法知道一个页面多长时间不再被访问。

#### **先进先出**

选择换出的页面是最先进入的页面。该算法会将那些经常被访问的页面也被换出，从而使缺页率升高。

#### **最近最久未使用（LRU）**

算法思路在于，虽然无法知道将来要使用的页面情况，但是可以知道过去使用页面的情况。LRU 将最近最久未使用的页面换出。

为了实现LRU，需要在内存中维护一个所有页面的链表。当一个页面被访问时，将这个页面移到链表表头。这样就能保证链表表尾的页面是最近最久未访问的。因为每次访问都需要更新链表，因此这种方式实现的LRU代价很高。

#### 近似LRU

为了解决LRU算法计算量过于复杂的问题，操作系统中一般使用近似LRU作为页面替换算法的实现。思路是增加一个使用位，当页被引用（读或写）时，引用位被硬件设置为1，由操作系统负责将引用位设置为0。

时钟算法是一种近似LRU算法。开始时，时钟指向一个页面，需要执行页面替换的操作时，如果指向的页面的使用位是1，把使用位置为0，指针指向下一个页面。指针会持续转动，直到找到一个使用位为0的页面。

任何周期性地清楚使用位，然后通过1和0判断替换哪个页的方法都是实现近似LRU的可行方法。

#### LRU代码实现

```c++
class LRUCache {
public:
    LRUCache(int capacity) {
        this->capacity = capacity;
    }
    
    int get(int key) {
        if (mapping.count(key) == 0) {
            return -1;
        } else {
            int value = mapping[key]->second;
            elements.erase(mapping[key]);
            elements.push_front({key, value});
            mapping[key] = elements.begin();
            return value;
        }
    }
    
    void put(int key, int value) {
        if (mapping.count(key) != 0) {
            elements.erase(mapping[key]);
        } else {
            if (elements.size() == capacity) {
                int del = elements.back().first;
                elements.pop_back();
                mapping.erase(del);
            }
        }
        elements.push_front({key, value});
        mapping[key] = elements.begin();
    }

private:
    int capacity;
    unordered_map<int, list<pair<int, int>>::iterator> mapping;
    list<pair<int, int>> elements;
};
```

关键点：

使用两个数据结构：双向链表和哈希表。双向链表负责存储LRU中的键值对，链表中第一个元素是最近访问的元素，以此类推。哈希表存放每个健和对应的键值对位置。

### malloc底层实现

[https://blog.csdn.net/maokelong95/article/details/51989081](https://blog.csdn.net/maokelong95/article/details/51989081)

glibc malloc采用ptmalloc作为内置的内存分配器。ptmalloc的主要优化点在于多线程的环境下不会在malloc上耗费过多时间。

当两个线程同时调用 malloc 时，内存均会得以立即分配——每个线程都维护着单独的堆，各个堆被独立的空闲列表数据结构管理，因此各个线程可以并发地从空闲列表数据结构中申请内存。这种为每个线程维护独立堆与空闲列表数据结构的行为就「per thread arena」。

#### Multiple Arena

Arena的共享过程如下：

* 当主线程第一次调用 `malloc` 时，已经建立的 main arena 会被没有任何竞争地使用；
* 当 thread 1 和 thread 2 第一次调用 `malloc` 时，一块新的 arena 将被创建，且将被没有任何竞争地使用。此时线程和 arena 之间存在一一映射关系；
* 当 thread3 第一次调用 `malloc` 时，arena 的数量限制被计算出来，结果显示已超出，因此尝试复用已经存在的 arena（也即 Main arena 或 Arena 1 或 Arena 2）；
  * 一旦遍历到可用 arena，就开始自旋申请该 arena 的锁；
  * 如果上锁成功（比如说 main arena 上锁成功），就将该 arena 返回用户；
  * 如果没找到可用 arena，thread 3 的 `malloc` 将被阻塞，直到有可用的 arena 为止。
* 当thread 3 调用 `malloc` 时(第二次了)，分配器会尝试使用上一次使用的 arena（也即，main arena），从而尽量提高缓存命中率。

arena的内存空间由堆组成，每个arena（除了main arena）都会持有一到多个堆。当空间耗尽时，main arena 通过 `sbrk` 拓展堆段，直至堆段「碰」到内存映射段；thread arena通过`mmap`申请一个新的堆（不一定是连续的内存空间）。

#### Chunk



#### 内存池机制

ptmalloc使用bins作为空闲列表数据结构，里面保存了free chunks，根据chunk的大小，分为以下几种类型：

- Fast bin；
- Unsorted bin；
- Small bin；
- Large bin。

##### Fast bin

大小为16-80字节的 chunk 被称为fast chunk。在所有的 bins 中，fast bins 路径享有最快的内存分配及释放速度。

* 每个 fast bin 都维护着一条 free chunk 的单链表，采用单链表是因为链表中所有 chunk 的大小相等，增删 chunk 发生在链表顶端即可。
* fast bin数量为10，每个bin的chunk大小8字节递增。
* 无需合并：两个相邻 chunk 不会被合并。虽然这可能会加剧内存碎片化，但也大大加速了内存释放的速度。

##### Unsorted bin

当 small chunk 和 large chunk 被 `free` 掉时，它们并非被添加到各自的 bin 中，而是被添加在unsorted bin 中。这使得分配器可以重新使用最近 `free` 掉的 chunk，从而消除了寻找合适 bin 的时间开销，进而加速了内存分配及释放的效率。

在内存分配的时候，在前后检索 fast/small bins 未果之后，在特定条件下，会将 unsorted bin 中的 chunks 转移到合适的 bin 中去。

##### Small bin

大小小于 512 字节的 chunk 被称为 small chunk，而保存 small chunks 的 bin 被称为small bin。在内存分配回收的速度上，small bin 比 large bin 更快。

- 每个 small bin 都维护着一条 free chunk 的双向循环链表。采用双向链表的原因是，small bins 中的 chunk 可能会从链表中部摘除。这里新增项放在链表的头部位置，而从链表的尾部位置移除项。
- small bin数量为62，每个bin的chunk大小8字节递增。
- 合并：相邻的 free chunk 将被合并，这减缓了内存碎片化，但是减慢了 `free` 的速度。

##### Large bin

大小大于等于 512 字节的 chunk 被称为large chunk，而保存 large chunks 的 bin 被称为 large bin。在内存分配回收的速度上，large bin 比 small bin 慢。

* 每个 large bin 都维护着一条 free chunk 的双向循环链表。采用双向链表的原因是，large bins 中的 chunk 可能会从链表中的任意位置插入及删除。
* 合并：两个相邻的空闲 chunk 会被合并。

#### Top Chunk

一个arena中最顶部的 chunk 被称为top chunk。它不属于任何 bin 。当所有 bin 中都没有合适空闲内存时，就会使用 top chunk 来响应用户请求。

当 top chunk 的大小比用户请求的大小大的时候，top chunk 会分割为两个部分：

- User chunk，返回给用户；
- Remainder chunk，剩余部分，将成为新的 top chunk。

当 top chunk 的大小比用户请求的大小小的时候，top chunk 就通过 `sbrk`（main arena）或 `mmap`（ thread arena）系统调用扩容。

### 动态内存分配策略

* 最优匹配：遍历空闲链表，找到所有大于等于请求内存大小的空闲块，把其中最小的一块分配出去，剩余的内存添加到空闲链表中。
* 最差匹配：和最优匹配相反，找到空闲链表中最大的一块空闲内存，然后把剩余的空闲内存加入到空闲链表中。
* 首次匹配：遍历空闲链表，直到遇上一个满足内存要求的空闲内存块。
* 下次匹配：和首次匹配类似，区别在于下次匹配需要记录上次匹配成功的空闲链表索引，搜索空闲链表时，从这个索引开始。这种方法避免对内存首部的频繁分配与释放。

### 常见内存分配错误

* 忘记分配内存，可能会导致段错误。
* 没有分配足够的内存，可能会导致缓冲区溢出。
* 忘记初始化已经分配的内存，可能会导致非初始化的内存读取。
* 忘记释放内存，这样会造成内存泄漏。在长时间运行的程序中，如果存在内存泄漏，可能会导致内存不足，重新启动。
* 在用完之前释放内存，会导致空悬指针错误。
* 重复释放内存。
* 错误地调用free。

### 内部碎片和外部碎片

当分配的内存被释放后，可用的内存空间会被分为不连续的小块，这个时候容易产生外部碎片问题。如果空闲内存的总量超过了申请的内存大小，但是由于这些内存并不连续，最后导致内存分配失败，这种情况称为外部碎片。

如果分配程序给出的内存超过了请求的大小，已分配的内存中未被使用的部分就是内部碎片。这种形式的内存浪费发生在已分配单元的内部。

### Linux伙伴系统

Linux伙伴系统为内核提供了一种用于**分配一组连续的页**而建立的一种高效的分配策略，并有效的解决了外碎片问题。

在系统中，空闲空间被视为一块大小为$2^N$的连续内存空间。在Linux中，把所有的空闲页分组为11个块链表。

当向内核请求分配空间时，向上取到$2^i$，然后朝着空闲页块。如果对应的块链表中没有空闲页块，则在更大的页块链表中找。当分配的页块中有多余的页时，伙伴系统根据多余的页框大小插入到对应的空闲页块链表中。

当释放时，内核首先计算出伙伴地址的位置。伙伴满足以下三个条件：

* 两个块具有相同的大小。
* 它们的物理地址是**连续**的。
* 从同一个更大的块中分配得来。

如果找到了该内存块的伙伴，确保该伙伴的所有页都是空闲的，以便进行合并。内存继续检查合并后页块的“伙伴”并检查是否可以合并。

### slab内存分配器

slab用于内核数据结构的分配和释放，可以加快内存的分配和释放速度，同时避免了空闲链表不能全局控制的问题。针对的对象时频繁分配和释放的内存数据结构，例如进程控制块、inode。slab相当于内核通用数据结构的缓存层。

slab有以下几个优化点：

* 高速缓存是一块连续的内存空间，这样做避免内存碎片产生。
* 回收的对象可以优先被投入到下一次分配中，这些对象大概率还在CPU高速缓存中，可以提升性能。
* 对存放对象进行着色，均匀映射到不同的缓存行，提升效率。
* 提供了对齐标志，可以按照缓存行对齐，或按照指针对齐。

slab把内存划分为不同的高速缓存组，每个高速缓存组放置不同类型的对象，每个对象对应一组高速缓存。分配内存时直接从缓存中取一块空闲的内存，释放的时候直接归还到slab中。

slab内存空间有以下的状态：

* 部分空闲。
* 



### Linux虚拟内存实现

Linux内核把进程的虚拟空间视为一些区域的集合，这些区域是已分配的虚拟内存的连续片。不属于某个区域的虚拟内存是不存在的。这种设计允许虚拟地址空间有空隙，不用记录没有用到的虚拟内存空间。

Linux为每一个进程维护一个mm_struct结构，描述了虚拟内存的当前状态。其中pgd字段指向进程一级页表的基地址，而mmap指向一个由vm_area_structs组成的链表，每个vm_area_structs都描述了一个当前进程空间的一个区域。pgd地址存储在CR3控制寄存器中。

为什么同时使用一个红黑树和链表保存所有的地址空间？链表有助于高效、简单的遍历所有的已分配地址空间，而红黑树支持高效率的特定地址空间查找。

每个mm_struct通过双向链表连接在一起，表示所有进程的虚拟地址空间，链表的头元素是init（1号进程）的地址空间，在执行fork的过程中需要对这个链表加锁，防止并发访问。

### 进程间通信的方法

进程间通信工具可以根据功能分为三类：

* 通信：关注进程之间的数据交换。
* 同步：关注进程和线程操作之间的同步。
* 信号

通信工具可以在进程之间交换数据，可以被分为以下两类：

* 数据传输工具：要求在用户和内核之间进行两次数据传输。数据传输工具可以分为以下几个类别：
  * 字节流：通过管道、FIFO、字节流socket交换的数据是一个无分隔符的字节流。
  * 消息：通过消息队列、数据报socket交换的数据是一个有分隔符分隔的消息。
* 共享内存：允许进程将数据放在进程共享的一块内存中完成数据的交换。由于通信无需系统调用以及用户和内核之间的数据传输，共享内存的速度非常快。

同步工具可以协调进程的操作，包括了信号量、文件锁。

#### 通信机制的特点

| IPC机制  | 数据抽象 |  参与者  |   方向    |                           内核实现                           |
| :------: | :------: | :------: | :-------: | :----------------------------------------------------------: |
|   管道   |  字节流  | 两个进程 |   单向    | 通常以FIFO的缓冲区来管理数据，分匿名管道和具名管道两种实现。 |
| 消息队列 |   消息   |  多进程  | 单向/双向 |      队列的组织方式，通过文件的权限来管理对队列的访问。      |
|  信号量  |  计数器  |  多进程  | 单向/双向 |   内核维护共享计数器，通过文件的权限来管理对计数器的访问。   |
| 共享内存 | 内存区域 |  多进程  | 单向/双向 |    内核维护共享内存，通过文件的权限来管理对计数器的访问。    |
|   信号   | 时间编号 |  多进程  |   单向    | 为线程/进程维护信号等待队列，通过用户/组的权限管理信号的操作 |
|  套接字  | 数据报文 | 两个进程 | 单向/双向 | 有基于IP/端口和基于文件路径的寻址方式。利用网络管理通信连接。 |

#### 管道

管道分为匿名管道和具名管道。

如果管道关闭了，那么下面的操作会有以下结果：

* 如果读一个已经关闭的管道，在所有的数据都被读取完毕后，read返回0。
* 如果写一个已经关闭的管道，产生SIGPIPE信号。

匿名管道通过pipe函数创建，fd[0]用于读，fd[1]用于写。

```C
#include <unistd.h>
int pipe(int fd[2]);
```

匿名管道是一个特殊的文件，仅仅在内存中存在，在磁盘中是没有的。

匿名管道有以下两个特性：

* 数据的流向是单向的，管道只能从一个进程读取，另一个进程写入（半双工通信）。
* 管道只能在父子进程或者兄弟进程之间使用。

匿名管道的底层实现如下。

<div align="center">
  <img src="images/53cd9ade-b0a6-4399-b4de-7f1fbd06cdfb.png" />
</div>

具名管道（FIFO）去除了管道只能在父子进程间或者兄弟进程间使用的限制。

```C
#include <sys/stat.h>
int mkfifo(const char *path, mode_t mode);
int mkfifoat(int fd, const char *path, mode_t mode);
```

FIFO主要有以下两个作用：

1. 在客户-服务器应用程序中，FIFO 用作汇聚点，在客户进程和服务器进程之间传递数据。
2. shell通过FIFO将数据从一条管道传递到另一条管道，无需创建中间文件。

不管是匿名管道还是命名管道，进程写入的数据都是缓存在内核中，另一个进程读取数据时候自然也是从内核中获取，同时通信数据都遵循先进先出原则，不支持 lseek 之类的文件定位操作。

管道这种通信方式效率比较低下，不适合进程之间频繁的交换数据。管道的优势在于使用简单，容易知道管道中的数据已经被读取了。

#### 消息队列

消息队列是消息的链接表，存储在内核中，由消息队列标识符标识。在发送数据时，消息会被分割成一块一块的数据单元（消息体）。消息队列有如下特点：

* 没有父子进程之间通信的限制，任意进程都可以通过消息队列实现进程间通信。
* 通过系统函数实现消息发送与接收的同步，不需要用户关心。
* 消息队列可以指定消息的类型，接收方不一定只能接收消息队列中的第一条消息。

消息队列也存在一些限制：

* 消息队列存在内核态和用户态的数据拷贝开销。
* 消息队列对于较大数据的传输有限制。消息队列对于可发送的最长长度的消息大小以及消息队列的总长度大小都有限制。

#### 共享内存

共享内存解决了管道和消息队列在用户态和内核态之间拷贝数据的过程。由于没有用户态和系统态之间的上下文切换，共享内存是最快的进程间通信方法。

共享内存采用虚拟内存的技术，让每个进程都拿出一块虚拟地址空间，映射到相同的物理地址上。一个进程写入的数据，另一个进程可以立马看到，无需在用户态和内核态之间传递数据，提升了进程间通信的速度。

共享内存的优点在于简单且高效，没有用户态和内核态之间数据的拷贝开销，不需要系统调用。共享内存的缺点是没有提供同步机制，需要使用其他的手段实现同步。

#### 信号量

信号量是一个整数值，主要用于实现进程间的互斥与同步，可以使用两个函数来操作它。

* sem_wait()：把信号量值减一，要么立即返回，要么会让调用的线程挂起，直到之后的一个post操作唤醒。
* sem_post()：直接增加信号量的值，如果当前有等待的线程，唤醒其中一个。
* 如果信号量为负值，其绝对值就是等待的线程个数。

如果信号量的初始值为1，信号量实现的是互斥量的功能。

如果信号量的初始值为0，信号量实现的是条件变量的功能。

#### 套接字

套接字提供了一种既可以用于同一台主机上，又可以用于不同主机上的进程间通信的方法。

套接字可以分为因特网套接字和UNIX域套接字，UNIX域套接字只能用于同一主机不同进程间的通信。

UNIX域套接字和因特网套接字的区别在于，UNIX域套接字不需要执行协议处理，不需要添加和删除网络报文段，不需要产生校验和，不需要发送确认报文，仅仅复制数据，效率更高。

#### 信号

如果有异常情况，需要使用信号通知进程。信号事件的来源主要是硬件来源（键盘输入）和软件来源（kill命令）。

信号是进程间通信机制中唯一的异步通信机制。如果一个线程接收到了一个信号，可以有以下几种信号处理方式：

1. 执行默认操作。Linux对每种信号都规定了默认操作。
2. 捕捉信号。进程可以自己定义一个信号处理函数，当信号发生时执行相应的信号处理函数。
3. 忽略信号。不希望处理某些信号的时候，就可以忽略该信号，不做任何处理。 （除了SIGKILL 和 SIGSTOP）

### 线程同步的方法

#### 临界区







#### Mutex和Semaphore的区别

Mutex 相比信号量增加了所有权的概念，一只锁住的 Mutex 只能由给它上锁的线程解开，只有系铃人才能解铃。Mutex 的功能也就因而限制在了构造临界区上。

一元信号量则可以由任一线程解开。这样多出来的一份语义，就是解决读者-写者问题的工具。比如某进程读取磁盘并进入睡眠，等待中断读取盘块结束之后来唤醒它。这就是可以祭出一元信号量的一个情景，而 Mutex 是解决不了的。『信号量』 这个词本身来自火车站的信号灯，其实本来就暗含着一层”通知“的含义。

> 作者：fleuria
> 链接：https://www.zhihu.com/question/47704079/answer/136200849
> 来源：知乎
> 著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。

### 为什么条件变量要配合互斥量使用？

为了保护条件变量检查的条件。

假设有下面的代码，父线程调用thr_join, 子线程调用thr_exit。
```C
void thr_exit() {
    done = 1;
    pthread_cond_signal(&c);
}

void thr_join() {
    if (done == 0) {           // p1
        pthread_cond_wait(&c); // p2
    }
}
```
若父线程执行完p1后，操作系统调度子线程执行。子线程执行完毕后退出。此时，父线程继续执行，当执行p2时休眠。在这种情况下，不会有任何线程能够唤醒父线程（此时只有一个线程正在运行），父线程会**一直睡眠**，无法被唤醒。

### 锁的底层实现

看博客：https://williamgrt.github.io/2021/01/02/mutex-implementation/

实现锁的想法很简单：用一个变量标志锁是否被占有。第一个线程进入临界区，调用lock，检查标志位是否为1，设置标志位为1。当调用unlock时，设置标志位为0。当其他的线程调用lock时，发现标志位为1，它会在while循环中自旋，直到有线程调用unlock。

这种实现的问题在于：while过程中有可能会产生中断，无法保证互斥性。

#### 基于自旋

一种方法是利用硬件提供的机制。锁的实现需要使用硬件提供的原子操作，这里可以使用test-and-set指令。

```C
static int flag=0;

void lock(){
  while(TestAndSet(&flag,1)==1); // spin-wait
  //flag=1;
}

void unlock(){
  flag=0;
}

int TestAndSet(int *ptr, int new) {
  int old = *ptr;
  *ptr = new;
  return old;
}
```

有些系统提供了compare-and-swap指令。

```C
int CompareAndSwap(int *ptr, int expected, int new) {
  int actual = *ptr;
  if (actual == expected) {
    *ptr = new;
  }
  return actual;
}
```

在处理器层面，compare-and-swap依赖于cmpxchgl指令。

```c
char compare_and_swap(int *ptr, int old, int new) {
    unsigned char ret;
    // Note that sete sets a ’byte’ not the word
    __asm__ __volatile__ (
      " lock\n"
      " cmpxchgl %2,%1\n"
      " sete %0\n"
      : "=q" (ret), "=m" (*ptr)
      : "r" (new), "m" (*ptr), "a" (old)
      : "memory");
    return ret;
}
```

**基于睡眠**

使用自旋存在一个问题：如果有N个线程同时竞争一个临界区，会浪费掉N-1个时间片。如果让没有竞争到锁的线程直接休眠，那么因为线程调度的不确定性，会造成有的线程被饿死。

因此，另一种锁的实现采用了基于休眠的方法。操作系统构建了休眠队列，如果一个线程没有竞争到锁，直接把自己加入到休眠队列中，当锁可用时再唤醒这个线程。通过队列控制谁会获得锁，避免产生线程饿死的情况。一种实现的方法如下。

```C

```

这种方法存在的问题：如果 `queue_add()` 和 `park()` 执行之间，有一个线程释放了锁，那么当前的线程在加入到阻塞队列后，立马就会被唤醒，这样会造成无谓的上下文切换，带来时间上的浪费。

一种解决方法是：使用一个新的系统调用 `setpark()`，让线程进入准备休眠的状态，如果此时有另一个线程执行了唤醒操作，当前线程立刻返回。

### 生产者-消费者问题

#### 基于互斥量和条件变量

```C
void *producer(void *arg) {
    int i;
    for (i = 0; i < loops; i++) {
    	Mutex_lock(&m);            // p1
    	while (num_full == max)    // p2
    	    Cond_wait(&empty, &m); // p3
    	do_fill(i);                // p4
    	Cond_signal(&fill);        // p5
    	Mutex_unlock(&m);          // p6
    }

    // end case: put an end-of-production marker (-1) 
    // into shared buffer, one per consumer
    for (i = 0; i < consumers; i++) {
    	Mutex_lock(&m);
    	while (num_full == max) 
    	    Cond_wait(&empty, &m);
    	do_fill(-1);
    	Cond_signal(&fill);
    	Mutex_unlock(&m);
    }

    return NULL;
}
                                                                               
void *consumer(void *arg) {
    int tmp = 0;
    // consumer: keep pulling data out of shared buffer
    // until you receive a -1 (end-of-production marker)
    while (tmp != -1) { 
    	Mutex_lock(&m);           // c1
    	while (num_full == 0)     // c2 
    	    Cond_wait(&fill, &m); // c3
    	tmp = do_get();           // c4
    	Cond_signal(&empty);      // c5
    	Mutex_unlock(&m);         // c6
    }
    return NULL;
}
```

关键点：

* 使用**一个互斥锁**保护临界区数据的读写。
* 使用 `while` 判断条件变量唤醒条件是否满足，防止虚假唤醒。
* 使用**两个条件变量**，保证生产者只能唤醒消费者，消费者只能唤醒生产者。

### 经典同步问题

#### 哲学家就餐问题

##### 问题描述

五个哲学家围着一张圆桌，每个哲学家面前放着食物。哲学家的生活有两种交替活动：吃饭以及思考。当一个哲学家吃饭时，需要先拿起自己左右两边的两根筷子，并且一次只能拿起一根筷子。

##### 解决方法

一种解决的思路为：每个哲学家首先获得自己左手边的筷子的锁，然后获取自己右手边的筷子的锁。结束时释放这些锁。

这种解决方法会带来死锁的问题，假设所有的哲学家都拿起了左手边的筷子（给他们加锁），这时候就没有任何一个哲学家可以获得自己右手边的筷子，整个系统陷入死锁。

一种解决的思路是破除循环依赖：更改某个或者某些哲学家的获取筷子的顺序。例如，第五个哲学家取筷子的顺序是先取右边的筷子，再去左边的筷子，就不会出现五个哲学家都拿着一个筷子，等待另一个筷子的情况。

#### 实现读写锁（读者-写者问题）

```C
typedef struct _rwlock_t {
    sem_t writelock;
    sem_t lock;
    int readers;
} rwlock_t;

void rwlock_init(rwlock_t *lock) {
    lock->readers = 0;
    Sem_init(&lock->lock, 1); 
    Sem_init(&lock->writelock, 1); 
}

void rwlock_acquire_readlock(rwlock_t *lock) {
    Sem_wait(&lock->lock);
    lock->readers++;
    if (lock->readers == 1)
			Sem_wait(&lock->writelock);
    Sem_post(&lock->lock);
}

void rwlock_release_readlock(rwlock_t *lock) {
    Sem_wait(&lock->lock);
    lock->readers--;
    if (lock->readers == 0)
			Sem_post(&lock->writelock);
    Sem_post(&lock->lock);
}

void rwlock_acquire_writelock(rwlock_t *lock) {
    Sem_wait(&lock->writelock);
}

void rwlock_release_writelock(rwlock_t *lock) {
    Sem_post(&lock->writelock);
}
```

### 死锁

#### 死锁的概念和产生原因

在多进程环境中，若每个进程分别持有特定资源，并且等待其他进程释放持有的资源，在为改变状态的情况下一直保持下去，就会造成死锁。

造成死锁的条件有如下几点：

* 互斥：每种资源只能由一个进程持有。
* 持有并等待：进程持有了资源，并且等待其他进程持有的资源。
* 非抢占： 进程获得的资源不能被抢占。
* 循环等待：进程之间存在一条环路，每个进程持有一个资源，并且等待下一个进程持有的资源。

#### 解决死锁的方法

解决死锁的方法主要有以下几点：死锁预防、死锁避免、死锁检测和恢复。

##### 死锁预防

核心思想是破坏产生死锁的四个条件。
* 循环等待：安排锁的获取顺序以避免死锁。
* 持有并等待：通过原子地抢锁解决。实际中，通过提供一个全局锁，保证代码在抢锁的过程中不会出现不合时宜的线程切换。
* 非抢占：系统提供了trylock()方法，会尝试获得锁，如果失败，返回-1。这种方法可能会造成**活锁**，两个线程一直重复这段序列，又都同时抢锁失败。
* 互斥：基于硬件指令，构造无锁数据结构完成相同的功能，例如**CAS（compare-and-swap）**指令。

##### 死锁避免

提前获取每个进程关于资源的使用信息，通过调度的方式避免死锁。可以采用诸如银行家算法完成。这类方法的局限性在于适用场景有限并且会限制系统的并发数，实际的使用不多。

##### 死锁检测和恢复

允许死锁发生，系统定期检查是否存在死锁情况，如果存在死锁就执行恢复程序。这种方法在数据库系统中有应用。

### 磁盘调度算法

#### 最短寻道时间优先

按照I/O请求队列排序，选择寻道时间最短的任务优先完成。这个方法主要的缺点是容易造成磁盘饥饿，离磁头较远的磁道无法完成I/O操作。

#### 电梯算法

磁头每次从外到内扫描一遍磁道，如果当前磁道有I/O任务，当时已经被磁头扫描过了，那么就要等到下一次扫描的时候执行I/O操作。

一种电梯算法的变种是C-SCAN，主要的改进方向是让磁头从外圈扫描到内圈，然后从内圈扫描到外圈。

#### 最短定位时间优先

根据旋转与寻道的相对时间决定下一个读取的磁盘块。（总是视情况而定）

通常在驱动器内部执行。

### 文件系统

#### 相关的数据结构

在Linux中，和文件相关的数据结构有以下四种：

* 超级块对象：代表一个具体的已安装的文件系统。该对象用于存储特定文件系统的信息。
* 索引节点对象：代表一个具体的文件，包含了内核在操作文件或目录的全部信息。索引节点是文件的唯一表示，它们之间一一对应。如果文件是磁盘文件，索引节点同样需要存储到磁盘上。
* 目录项对象：代表一个目录项，是路径的一个组成部分。路径的每一个组成部分都是一个文件。虽然可以使用索引节点对象表示每一个文件，但是为了方便查找，内核为每一个路径上的文件创建一个目录项对象。目录项纪录了文件的名字、索引节点指针以及与其他目录项的层级关联关系。目录想有内核创建并维护，不用写到磁盘上。
* 文件对象：代表由进程打开的文件，包含了访问模式、当前偏移量。文件对象代表在进程视角下的打开文件，对应唯一一个目录项对象。文件对象有内核创建和维护，不用存储在磁盘上。

#### 虚拟文件系统

虚拟文件系统提供了一种对文件系统的统一访问接口，程序不需要了解文件系统的工作原理即可使用提供的统一接口，可以对不同文件系统以及不同存储介质的文件进行读写操作。

#### 文件的存储

文件系统把磁盘划分为多个逻辑块，每一个的大小为4KB。一个文件系统把整个磁盘空间划分为以下几个部分：

* 数据区域：用于存放用户的数据。
* inode table：用于存放每个文件的inode。
* 空闲列表：用于指示磁盘中的数据块是空闲的还是被使用的，用于写入文件时分配新的数据块。
* 超级块：用于存储文件系统的信息。

inode中最重要的决定是如何引用数据块的位置，通常有以下几种做法：

* 链表法

在inode中只需要保存一个指向链表头节点的指针，如果需要处理较大的文件，就在这个数据块的末尾添加一个指针。这种做法无法直接访问数据块，只能通过指针顺序访问文件，并且数据块指针消耗了一定的存储空间。

因此，有些文件系统把链接各个数据块的指针显示放在内存的一张链接表中，每个表项存储指向下一个数据块的指针。这种方法提升了访问磁盘的速度，但是不适用于大磁盘。

* 索引法

在inode中保存一组指针，每个指针指向一个属于该文件的数据块。这使得文件的顺序和随机访问都很快。这种方法存在一定局限性，不能支持大文件。

为了支持更大的文件，可以使用一个间接指针，指向一个存储了数据块指针的数据块，这种不平衡树又称为多级索引。这种做法能够灵活的支持小文件和大文件的存放。

#### 空闲空间管理

系统为了记录哪个数据块和inode是空闲的，在分配新目录或者文件时就可以很快找到空闲的空间。常见的做法是使用两个位图（inode位图和数据块位图）标识。

#### 目录的组织

目录和普通文件的区别在于，目录文件的块里面保存的是目录里面一项一项的文件信息。最简单的保存格式就是列表，就是一项一项地将目录下的文件信息（如文件名、文件 inode、文件类型等）列在表里，如果需要删除一个文件，需要把多赢的条目做一个删除的标记，可以重复使用旧有的空间。

为了加速目录中文件的查找，可以使用哈希表保存目录格式。同时。为了减少 I/O 操作，把当前使用的文件目录缓存在内存，降低磁盘的操作次数，提升文件系统访问速度。

#### 读写文件的执行过程

1. 



### 参考资料

* 《操作系统导论》
* 《Linux内核设计与实现》
* 《UNIX环境高级编程》